# ğŸ“¦ Nominal: OAuth-based QuickBooks API Integration

## ğŸš€ Overview

**Nominal** is a backend system built with FastAPI and Docker that integrates with the QuickBooks Online API using OAuth 2.0. It allows secure token handling, periodic syncing of account data from QuickBooks, and provides endpoints for account querying and token management.

---

## âœ¨ Features

-   ğŸ” OAuth 2.0-based secure token management
-   ğŸ” Automatic token refresh logic
-   â° Scheduled background jobs using Celery and Celery Beat
-   ğŸ³ Fully Dockerized architecture (API, PostgreSQL, Redis, Worker, Beat)
-   ğŸ” RESTful API to search and retrieve QuickBooks accounts
-   ğŸ§¬ Database migrations with Alembic
-   ğŸ“¡ Centralized logging with Loggly

---

## ğŸ§° Tech Stack

-   **FastAPI** â€“ REST API framework
-   **SQLAlchemy** â€“ ORM for DB access
-   **PostgreSQL** â€“ Primary database
-   **Redis** â€“ Broker for Celery
-   **Celery** â€“ Background task queue
-   **Alembic** â€“ Schema migrations
-   **Docker** â€“ Container orchestration
-   **Loggly** â€“ Logging service

---

## ğŸ” QuickBooks OAuth Integration

This app uses [QuickBooks OAuth 2.0](https://developer.intuit.com/app/developer/qbo/docs/get-started) to authenticate with the QuickBooks API and fetch accounts. Tokens are securely stored and reused for scheduled tasks or manual triggers.

---

## ğŸ“ Project Structure

```bash
Nominal/
â”‚
â”œâ”€â”€ alembic/               # Alembic migration scripts
â”œâ”€â”€ core/                  # Configuration loading
â”œâ”€â”€ database/              # DB session and base
â”œâ”€â”€ models/                # SQLAlchemy ORM models
â”œâ”€â”€ routes/                # FastAPI route handlers
â”œâ”€â”€ schemas/               # Pydantic validation schemas
â”œâ”€â”€ services/              # Logic for OAuth and account sync
â”œâ”€â”€ tasks/                 # Celery tasks
â”œâ”€â”€ tests/                 # Unit tests
â”œâ”€â”€ utils/                 # Logging utils, etc.
â”œâ”€â”€ .env.example           # Sample environment config
â”œâ”€â”€ main.py                # App entrypoint
â”œâ”€â”€ Dockerfile             # Image instructions
â”œâ”€â”€ docker-compose.yml     # Multi-container services
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # Project documentation
```

---

## âš™ï¸ Setup with Docker (Recommended for Windows/Linux)

### âœ… Prerequisites

-   Docker
-   Docker Compose

---

### ğŸ“¥ [1. Clone the Repository](#ğŸ“¥-1-clone-the-repository)

```bash
git clone <repo-url>
cd nominal_QuickBooks
```

---

### ğŸ” [2. Configure Environment](#ğŸ”-2-configure-environment)

Copy and edit the `.env` file:

```bash
cp .env.example .env
```

ğŸ§¾ Example `.env`:

```ini
POSTGRES_DB=nominal
POSTGRES_USER=db_user
POSTGRES_PASSWORD=db_password

CLIENT_ID=your_qbo_client_id
CLIENT_SECRET=your_qbo_client_secret
REDIRECT_URI=http://localhost:8000/callback

DATABASE_URL_LOCAL=postgresql://db_user:db_password@localhost:5432/nominal
DATABASE_URL_DOCKER=postgresql://db_user:db_password@db:5432/nominal
DATABASE_URL_LAPTOP=postgresql://user:pass@host:5432/dbname

ENVIRONMENT=development
USE_DOCKER=true
USE_LAPTOP=false

LOGGLY_TOKEN=your-loggly-token

REDIS_HOST=redis
REDIS_PORT=6379
REDIS_USERNAME=
REDIS_PASSWORD=

CELERY_SCHEDULE_INTERVAL=600
```

---

### ğŸ³ 3. Run with Docker

```bash
docker-compose down -v  # Optional: clean previous state
docker-compose up --build
```

What this does:

-   ğŸ”§ Installs dependencies
-   â›“ï¸ Runs Alembic migrations
-   âœ… Runs unit tests
-   ğŸš€ Launches API + Celery Worker + Celery Beat

---

### ğŸŒ Access the API

```bash
http://localhost:8000
```

---

## âš™ï¸ Setup Locally (Without Docker)

### 1. Clone the Repository

```bash
git clone <repo-url>
cd nominal_QuickBooks
```

### 2. Create Environment

```bash
cp .env.example .env
```

### 3. Create Virtual Environment

```bash
# Windows
python -m venv venv

# Linux/macOS
python3 -m venv venv
```

### 4. Activate Virtual Environment

```bash
# Windows
venv\Scripts\activate

# Linux/macOS
source venv/bin/activate
```

### 5. Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 6. Create Database

Ensure PostgreSQL is running and youâ€™ve created the `nominal` database.

### 7. Run Migrations

```bash
alembic upgrade head
```

### 8. Run Tests

```bash
pytest tests/
```

### 9. Run the API Server

```bash
uvicorn main:app --reload
```

### 10. Run Celery Worker

```bash
celery -A tasks.tasks worker --pool=solo --loglevel=info
```

### 11. Run Celery Beat

```bash
celery -A tasks.tasks beat --loglevel=info
```

---

## ğŸ”Œ API Endpoints

| Method | Endpoint            | Description                            |
| ------ | ------------------- | -------------------------------------- |
| GET    | `/`                 | Initiate QuickBooks OAuth login        |
| GET    | `/callback`         | Handle redirect from QuickBooks        |
| GET    | `/accounts`         | Manually trigger account sync          |
| GET    | `/accounts/search`  | Search accounts                        |
| GET    | `/accounts/summary` | Show summary result by classification  |
| GET    | `/accounts/tree`    | Generate tree child/parent of accounts |
| GET    | `/health`           | Health check                           |

---

## ğŸªµ Logging

Log messages are sent to **Loggly** (if `LOGGLY_TOKEN` is set).

-   `celery.task` â†’ for Celery logs
-   `fastapi.middleware` â†’ for HTTP logs

---

## ğŸ§¹ Cleanup Tips

To remove all containers, volumes, and images:

```bash
docker-compose down -v --remove-orphans
```

To fully rebuild:

```bash
docker-compose down -v
docker-compose up --build
```

---

## ğŸ§  Additional Notes

-   Redis is required for Celery to function
-   Celery Beat will run scheduled jobs (e.g., syncing accounts)
-   Loggly setup requires a valid token from [Loggly](https://www.loggly.com/)
-   PostgreSQL data is stored in a Docker volume (`pgdata`) for persistence
